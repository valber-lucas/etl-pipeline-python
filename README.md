# ðŸš€ High-Performance ETL Pipeline (Python)

Pipeline de Engenharia de Dados capaz de processar e ingerir datasets massivos com consumo de memÃ³ria constante (O(1)).

## âš¡ Performance Benchmark
- **Dataset:** 1 MilhÃ£o de registros (CSV gerado sinteticamente).
- **Tempo de Processamento:** ~2.4 segundos.
- **EstratÃ©gia:** Generators (Streaming) + Batch Insert (SQL).

## ðŸ› ï¸ Tecnologias
- **Python 3.12+**
- **SQLite** (PersistÃªncia Relacional)
- **Logging** (Rastreabilidade Enterprise)
- **CI/CD:** GitHub Actions (Automated Testing)

## âš™ï¸ Arquitetura
O projeto resolve o problema de "Memory Overflow" ao ler arquivos maiores que a RAM disponÃ­vel:

1.  **Extract:** Leitura via `yield` (Lazy Loading).
2.  **Transform:** NormalizaÃ§Ã£o e validaÃ§Ã£o de tipos com `Type Hints`.
3.  **Load:** InserÃ§Ã£o em lotes (Batch Size: 5000) para otimizar I/O.

### Fluxo de Dados
```mermaid
graph LR
    A[CSV File] -->|Stream| B(Generator Python)
    B -->|Yield| C{Transform}
    C -->|Invalid| D[Log Error]
    C -->|Valid| E[Batch Buffer]
    E -->|Full?| F[(SQLite DB)]
    
    style A fill:#f9f,stroke:#333
    style F fill:#bbf,stroke:#333
```
